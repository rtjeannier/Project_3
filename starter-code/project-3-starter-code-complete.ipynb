{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Web Scraping for Indeed.com & Predicting Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "34681254-c802-462f-829d-8894d0772d08"
   },
   "source": [
    "In this project, we will practice two major skills: collecting data by scraping a website and then building a binary classifier.\n",
    "\n",
    "We are going to collect salary information on data science jobs in a variety of markets. Then using the location, title, and summary of the job we will attempt to predict the salary of the job. For job posting sites, this would be extraordinarily useful. While most listings DO NOT come with salary information (as you will see in this exercise), being to able extrapolate or predict the expected salaries from other listings can help guide negotiations.\n",
    "\n",
    "Normally, we could use regression for this task; however, we will convert this problem into classification and use a random forest classifier, as well as another classifier of your choice; either logistic regression, SVM, or KNN. \n",
    "\n",
    "- **Question**: Why would we want this to be a classification problem?\n",
    "- **Answer**: While more precision may be better, there is a fair amount of natural variance in job salaries - predicting a range be may be useful.\n",
    "\n",
    "Therefore, the first part of the assignment will be focused on scraping Indeed.com. In the second, we'll focus on using listings with salary information to build a model and predict additional salaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping job listings from Indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": true,
    "id": "7203e0c9-e437-4802-a6ad-7dc464f94436"
   },
   "source": [
    "We will be scraping job listings from Indeed.com using BeautifulSoup. Luckily, Indeed.com is a simple text page where we can easily find relevant entries.\n",
    "\n",
    "First, look at the source of an Indeed.com page: (http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=10\")\n",
    "\n",
    "Notice, each job listing is underneath a `div` tag with a class name of `result`. We can use BeautifulSoup to extract those. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. Use BeautifulSoup to parse the page and extract all results (HINT: Look for div tags with class name result)\n",
    "The URL here has many query parameters\n",
    "- q for the job search\n",
    "- This is followed by \"+20,000\" to return results with salaries (or expected salaries >$20,000)\n",
    "- l for a location\n",
    "- start for what result number to start on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l=New+York&start=100\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roland/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/roland/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "html = requests.get(URL)\n",
    "soup = BeautifulSoup(html.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at one result more closely. A single result looks like\n",
    "```JSON\n",
    "<div class=\" row result\" data-jk=\"2480d203f7e97210\" data-tn-component=\"organicJob\" id=\"p_2480d203f7e97210\" itemscope=\"\" itemtype=\"http://schema.org/JobPosting\">\n",
    "<h2 class=\"jobtitle\" id=\"jl_2480d203f7e97210\">\n",
    "<a class=\"turnstileLink\" data-tn-element=\"jobTitle\" onmousedown=\"return rclk(this,jobmap[0],1);\" rel=\"nofollow\" target=\"_blank\" title=\"AVP/Quantitative Analyst\">AVP/Quantitative Analyst</a>\n",
    "</h2>\n",
    "<span class=\"company\" itemprop=\"hiringOrganization\" itemtype=\"http://schema.org/Organization\">\n",
    "<span itemprop=\"name\">\n",
    "<a href=\"/cmp/Alliancebernstein?from=SERP&campaignid=serp-linkcompanyname&fromjk=2480d203f7e97210&jcid=b374f2a780e04789\" target=\"_blank\">\n",
    "    AllianceBernstein</a></span>\n",
    "</span>\n",
    "<tr>\n",
    "<td class=\"snip\">\n",
    "<nobr>$117,500 - $127,500 a year</nobr>\n",
    "<div>\n",
    "<span class=\"summary\" itemprop=\"description\">\n",
    "C onduct quantitative and statistical research as well as portfolio management for various investment portfolios. Collaborate with Quantitative Analysts and</span>\n",
    "</div>\n",
    "</div>\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this has some more verbose elements removed, we can see that there is some structure to the above:\n",
    "- The salary is available in a nobr element inside of a td element with class='snip.\n",
    "- The title of a job is in a link with class set to jobtitle and a data-tn-element=\"jobTitle.\n",
    "- The location is set in a span with class='location'.\n",
    "- The company is set in a span with class='company'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write 4 functions to extract these items (one function for each): location, company, job title, and salary.Â¶\n",
    "Example\n",
    "```python\n",
    "def extract_location_from_result(result):\n",
    "    return result.find ...\n",
    "```\n",
    "\n",
    "##### - Make sure these functions are robust and can handle cases where the data/field may not be available.\n",
    ">- Remember to check if a field is empty or None for attempting to call methods on it\n",
    ">- Remember to use try/except if you anticipate errors.\n",
    "\n",
    "- **Test** the functions on the results above and simple examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_location_from_result(result):\n",
    "    values = result.find_all(itemprop='addressLocality')\n",
    "    if values != None:\n",
    "        temp = list(map(lambda a: a.get_text(), values))\n",
    "        if len(temp) == 1:\n",
    "            return temp[0]\n",
    "        else:\n",
    "            return tuple(temp)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_salary_from_result(result):\n",
    "    values = result.findAll('span',class_='no-wrap')\n",
    "    if values != None:\n",
    "        # There are a number of salaries that are ranges, so I am spliting on white space and keeping\n",
    "        # just the values that have a dollar sign.\n",
    "        temp = list(map(lambda a: list(filter(lambda b: '$' in b, a.get_text().split(' '))),values))\n",
    "        \n",
    "        # Getting the first\n",
    "        if len(temp) != 0:\n",
    "            temp = temp[0]\n",
    "            \n",
    "        if len(temp) == 1:\n",
    "            return clean_salary(temp[0])\n",
    "        elif len(temp) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return clean_salary(tuple(temp))\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_salary_info_from_result(result):\n",
    "    values = result.findAll('span',class_='no-wrap')\n",
    "    if values != None:\n",
    "        # There are a number of salaries that are ranges, so I am spliting on white space and keeping\n",
    "        # just the values that have a dollar sign.\n",
    "        temp = list(map(lambda a: list(filter(lambda b: ('year' in b) or ('hour' in b) or ('day' in b) or ('week' in b) or ('month' in b), a.get_text().split(' '))),values))\n",
    "        \n",
    "        # Getting the first\n",
    "        if len(temp) != 0:\n",
    "            temp = temp[0]\n",
    "            \n",
    "        if len(temp) == 1:\n",
    "            return temp[0]\n",
    "        elif len(temp) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return tuple(temp)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_job_title_from_result(result):\n",
    "    values = result.find('a', attrs={\"data-tn-element\":'jobTitle'})\n",
    "    temp = []\n",
    "    if values != None:\n",
    "        temp.append(values[\"title\"])\n",
    "#         for v in values:\n",
    "#             if v != None:\n",
    "#                 #print(type(v))\n",
    "#                 temp.append(v)\n",
    "#             else:\n",
    "#                 temp.append(None)\n",
    "        if len(temp) == 1:\n",
    "            return temp[0]\n",
    "        else:\n",
    "            return tuple(temp)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#xtract_job_title_from_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_company_from_result(result):\n",
    "    values = result.find_all(class_='company')\n",
    "    temp = []\n",
    "    if values != None:\n",
    "        for v in values:\n",
    "            if v != None:\n",
    "                # I am getting rid of new line characters and removing excess whitespace that seems to pop up.\n",
    "                temp.append(v.find(itemprop=\"name\").get_text().replace(\"\\n\",\"\").strip())\n",
    "            else:\n",
    "                temp.append(None)\n",
    "    else:\n",
    "        temp.append(None)\n",
    "    if len(temp) == 1:\n",
    "        return temp[0]\n",
    "    else:\n",
    "        return tuple(temp)\n",
    "\n",
    "#extract_company_from_result(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def extract_description_from_result(result):\n",
    "    values = result.find(class_='summary')\n",
    "    temp = []\n",
    "    if values != None:\n",
    "        return values.get_text().replace('\\n','')\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_sponsored_result(result):\n",
    "    values=result.find(class_='sponsoredGray')\n",
    "    if values != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [],
   "source": [
    "from re import sub\n",
    "from decimal import Decimal\n",
    "\n",
    "def clean_salary(salary_string):\n",
    "    # Salaries could come in as a pair or as a single. Singles should be straight strings and pairs should be tuples\n",
    "    if type(salary_string) == tuple:\n",
    "        # Using recursion here to parse the individual values if i get more than one.\n",
    "        parsed = [clean_salary(s) for s in salary_string]\n",
    "        return np.mean(parsed)\n",
    "    \n",
    "    if type(salary_string) in [int, float]:\n",
    "        return salary_string\n",
    "    elif salary_string != None:\n",
    "        value = float(sub(r'[^\\d.]', '', salary_string))\n",
    "        return value\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "# I would like to get the cities from my cost of living data set.\n",
    "df_cost_living = pd.read_csv(\"~/Workspace/Data/cost_of_living.csv\")\n",
    "df_cost_living['search_location'] = df_cost_living.city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_template = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 1500 # Set this to a high-value (5000) to generate more results. \n",
    "# # Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "# cities =  set(['New+York', 'Chicago', 'San+Francisco', 'Austin', 'Seattle', \n",
    "#     'Los+Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Pittsburgh', \n",
    "#     'Portland', 'Phoenix', 'Denver', 'Houston', 'Miami', 'Baltimore'])\n",
    "\n",
    "cities = df_cost_living.city[df_cost_living.country == \"United States\"]\n",
    "\n",
    "city_dict = {}\n",
    "\n",
    "df = pd.DataFrame(columns = ['job_title', 'salary', 'location', 'company','description','search_location','salary_info'])\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "time1 = time.time()\n",
    "file_path = \"~/Workspace/Data/indeed_scraped.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "a0f701e0-80bd-40ba-9101-4535860c0968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on: New York City time: 24.983976125717163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roland/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/roland/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on: San Francisco time: 85.34972476959229\n",
      "on: Washington D.C. time: 126.25852942466736\n",
      "on: Honolulu time: 164.37589836120605\n",
      "on: San Jose time: 196.8243613243103\n",
      "on: Boston time: 245.35741329193115\n",
      "on: Maui time: 285.38808941841125\n",
      "on: Oakland time: 315.600869178772\n",
      "on: Los Angeles time: 356.95254158973694\n",
      "on: Seattle time: 398.1918468475342\n",
      "on: San Diego time: 453.5450847148895\n",
      "on: Chicago time: 498.24929690361023\n",
      "on: Boulder time: 540.5994446277618\n",
      "on: Philadelphia time: 581.3341801166534\n",
      "on: Sacramento time: 623.7558052539825\n",
      "on: Portland time: 672.1765425205231\n",
      "on: Anchorage time: 715.8028628826141\n",
      "on: Denver time: 770.6614933013916\n",
      "on: Miami time: 830.8518986701965\n",
      "on: Minneapolis - St. Paul time: 873.7945756912231\n",
      "on: Baltimore time: 939.1504876613617\n",
      "on: Providence time: 996.8945245742798\n",
      "on: Atlanta time: 1052.824295282364\n",
      "on: Hartford time: 1117.3798699378967\n",
      "on: Burlington time: 1169.0015277862549\n",
      "on: Tacoma time: 1222.9123373031616\n",
      "on: Fort Lauderdale time: 1276.7756202220917\n",
      "on: Dallas time: 1327.5629320144653\n",
      "on: Austin time: 1384.027110338211\n",
      "on: Salt Lake City time: 1447.280911207199\n",
      "on: Houston time: 1512.9220058918\n",
      "on: Nashville time: 1580.8743150234222\n",
      "on: Pittsburgh time: 1653.2006056308746\n",
      "on: New Orleans time: 1718.8977220058441\n",
      "on: Grand Rapids time: 1784.8005089759827\n",
      "on: Fort Worth time: 1844.2363319396973\n",
      "on: Milwaukee time: 1912.3290374279022\n",
      "on: Charlotte time: 1974.300106048584\n",
      "on: Las Vegas time: 2042.5794019699097\n",
      "on: Tampa time: 2105.0435461997986\n",
      "on: Reno time: 2176.633214712143\n",
      "on: Riverside time: 2246.295428276062\n",
      "on: Oklahoma City time: 2314.4169738292694\n",
      "on: St. Louis time: 2377.425784111023\n",
      "on: Orlando time: 2443.358244419098\n",
      "on: Cleveland time: 2521.8034961223602\n",
      "on: Buffalo time: 2593.6268658638\n",
      "on: Fresno time: 2664.3936240673065\n",
      "on: Jacksonville time: 2732.9649431705475\n",
      "on: Colorado Springs time: 2806.480466604233\n",
      "on: Raleigh time: 2875.6197485923767\n",
      "on: Cincinnati time: 2948.4429273605347\n",
      "on: Kansas City time: 3029.795221567154\n",
      "on: Tulsa time: 3103.5142171382904\n",
      "on: Phoenix time: 3187.997974395752\n",
      "on: Richmond time: 3270.655209541321\n",
      "on: Columbus time: 3350.6506867408752\n",
      "on: Wichita time: 3431.9526159763336\n",
      "on: Indianapolis time: 3512.8729734420776\n",
      "on: Albuquerque time: 3597.645285129547\n",
      "on: San Antonio time: 3677.830987930298\n",
      "on: Memphis time: 3767.2237663269043\n",
      "on: Knoxville time: 3852.1549139022827\n",
      "on: Louisville time: 3933.011260032654\n",
      "on: Flint time: 4018.038206100464\n",
      "on: Detroit time: 4056.9816014766693\n",
      "on: Boise time: 4146.290464401245\n",
      "on: Tucson time: 4220.612740278244\n",
      "4306.815292358398\n"
     ]
    }
   ],
   "source": [
    "for city in cities:\n",
    "    city_dict[city] =[]\n",
    "    \n",
    "    print(\"on: \" + city + \" time: \" + str(time.time() - time1))\n",
    "    \n",
    "    city = city.replace(' ','+')\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "\n",
    "        URL = url_template.format(city,start)\n",
    "        html = requests.get(URL)\n",
    "        soup = BeautifulSoup(html.text)\n",
    "        #city_dict[city].append(soup.find_all(class_=' row result'))\n",
    "        \n",
    "        # iterating through row results\n",
    "        for r in soup.find_all(class_='result'):\n",
    "            \n",
    "            if not is_sponsored_result(r):\n",
    "                df.loc[i] = [extract_job_title_from_result(r),\n",
    "                            extract_salary_from_result(r),\n",
    "                            extract_location_from_result(r),\n",
    "                            extract_company_from_result(r),\n",
    "                            extract_description_from_result(r),\n",
    "                            city.replace('+',' '),\n",
    "                            extract_salary_info_from_result(r)] #replacing + with whitespcae\n",
    "                # index rows with i count\n",
    "                i+=1\n",
    "                # short sleep to stop over hitting the server\n",
    "                time.sleep(.001)\n",
    "                \n",
    "                #saving csv occassionally. jumping by 500s.\n",
    "                if i % 500 == 0:\n",
    "                    if j == 0:\n",
    "                        # if first selection I am writing overtop existing file.\n",
    "                         df.iloc[j:j+i].to_csv(file_path, index=False)\n",
    "                    else:\n",
    "                        # appending if it is not the first write of this selection\n",
    "                        df.iloc[j:j+i].to_csv(file_path,mode='a', header=False, index=False)\n",
    "                    # updating j\n",
    "                    j+=1\n",
    "\n",
    "time2 = time.time()\n",
    "print(time2 - time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "20339c09-5032-4e27-91be-286e9b46cd13"
   },
   "source": [
    "#### Use the functions you wrote above to parse out the 4 fields - location, title, company and salary. Create a dataframe from the results with those 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(columns = ['job_title', 'salary', 'location', 'company','description','search_location','salary_info'])\n",
    "# i = 0\n",
    "# for k in city_dict.keys():\n",
    "#     for row in city_dict[k]:\n",
    "#         for r in row:\n",
    "\n",
    "#             if not is_sponsored_result(r):\n",
    "#                 df.loc[i] = [extract_job_title_from_result(r),\n",
    "#                             extract_salary_from_result(r),\n",
    "#                             extract_location_from_result(r),\n",
    "#                             extract_company_from_result(r),\n",
    "#                             extract_description_from_result(r),\n",
    "#                             k.replace('+',' '),\n",
    "#                             extract_salary_info_from_result(r)] #replacing + with whitespcae\n",
    "#                 # index rows with i count\n",
    "#                 i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>search_location</th>\n",
       "      <th>salary_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Engineer (Associate) - Intell...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY 10001 (Chelsea area)</td>\n",
       "      <td>JP Morgan Chase</td>\n",
       "      <td>JP Morgan Intelligent Solutions (JPMIS) is a n...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>GameChanger</td>\n",
       "      <td>As a Data Analyst, youâll transform the teraby...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>75000.0</td>\n",
       "      <td>New York, NY 10022 (Midtown area)</td>\n",
       "      <td>First Derivatives</td>\n",
       "      <td>Data Scientists explore vast amounts of inform...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist, Forecast Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NBCUniversal</td>\n",
       "      <td>Experience with data visualization techniques ...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist, Analytics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>The Data Scientist Analytics role has work acr...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title   salary  \\\n",
       "0  Machine Learning Engineer (Associate) - Intell...      NaN   \n",
       "1                                     Data Scientist      NaN   \n",
       "2                                     Data Scientist  75000.0   \n",
       "3                   Data Scientist, Forecast Analyst      NaN   \n",
       "4                          Data Scientist, Analytics      NaN   \n",
       "\n",
       "                            location            company  \\\n",
       "0  New York, NY 10001 (Chelsea area)    JP Morgan Chase   \n",
       "1                       New York, NY        GameChanger   \n",
       "2  New York, NY 10022 (Midtown area)  First Derivatives   \n",
       "3                       New York, NY       NBCUniversal   \n",
       "4                       New York, NY           Facebook   \n",
       "\n",
       "                                         description search_location  \\\n",
       "0  JP Morgan Intelligent Solutions (JPMIS) is a n...   New York City   \n",
       "1  As a Data Analyst, youâll transform the teraby...   New York City   \n",
       "2  Data Scientists explore vast amounts of inform...   New York City   \n",
       "3  Experience with data visualization techniques ...   New York City   \n",
       "4  The Data Scientist Analytics role has work acr...   New York City   \n",
       "\n",
       "  salary_info  \n",
       "0        None  \n",
       "1        None  \n",
       "2        year  \n",
       "3        None  \n",
       "4        None  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "ff98ce64-78a7-441f-a675-63464e32c834"
   },
   "source": [
    "Lastly, we need to clean up salary data. \n",
    "\n",
    "1. Only a small number of the scraped results have salary information - only these will be used for modeling.\n",
    "1. Some of the salaries are not yearly but hourly or weekly, these will not be useful to us for now\n",
    "1. Some of the entries may be duplicated\n",
    "1. The salaries are given as text and usually with ranges.\n",
    "\n",
    "#### Find the entries with annual salary entries, by filtering the entries without salaries or salaries that are not yearly (filter those that refer to hour or week). Also, remove duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>location</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>search_location</th>\n",
       "      <th>salary_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Engineer (Associate) - Intell...</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10001 (Chelsea area)</td>\n",
       "      <td>JP Morgan Chase</td>\n",
       "      <td>JP Morgan Intelligent Solutions (JPMIS) is a n...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>GameChanger</td>\n",
       "      <td>As a Data Analyst, youâll transform the teraby...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist, Forecast Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NBCUniversal</td>\n",
       "      <td>Experience with data visualization techniques ...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist, Analytics</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>The Data Scientist Analytics role has work acr...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Test &amp; Learn Analytics</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10003 (Greenwich Village area)</td>\n",
       "      <td>J.Crew Group, Inc.</td>\n",
       "      <td>Data Scientist â Test and Learn Analytics. Han...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>Diaspark</td>\n",
       "      <td>Team-oriented (we run a meritocracy), creative...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Blue State Digital</td>\n",
       "      <td>Use data to build a better world. You will be ...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10012 (Little Italy area)</td>\n",
       "      <td>Meetup</td>\n",
       "      <td>3+ years working with data analytics, data war...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>ThreatMetrix</td>\n",
       "      <td>As a Data Scientist, youâll use data from the ...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Scientist - Pricing</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10003 (Greenwich Village area)</td>\n",
       "      <td>J.Crew Group, Inc.</td>\n",
       "      <td>J.Crew is seeking a Data Scientist with an emp...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Tumblr</td>\n",
       "      <td>Influence product decisions through data analy...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>Pienso</td>\n",
       "      <td>Youâre a machine learning backend engineer, ap...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>LearnVest</td>\n",
       "      <td>Ability to tell a story with data â What does ...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Multi-Asset Quantitative Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Voya Financial</td>\n",
       "      <td>Thoughtful process of analyzing data and probl...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>HelloFresh</td>\n",
       "      <td>Data Scientist Job Description:. A data junkie...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Applied Researcher / Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10011 (Chelsea area)</td>\n",
       "      <td>eBay Inc.</td>\n",
       "      <td>Youâll work with world-class data scientists a...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>CompIQ</td>\n",
       "      <td>We're looking for a highly analytical data sci...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Scientist (Associate) - Wholesale Solutio...</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10001 (Chelsea area)</td>\n",
       "      <td>JP Morgan Chase</td>\n",
       "      <td>JPMIS Data Scientist is responsible for develo...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Quantitative Researcher/Analyst â Statistical ...</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Global Trading Systems</td>\n",
       "      <td>We are looking for a quantitative researcher w...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Scientist, Economic Consulting Practice</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10036</td>\n",
       "      <td>FTI Consulting, Inc.</td>\n",
       "      <td>Data Scientist, Economic Consulting Practice. ...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Scientist II</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10112 (Midtown area)</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>Solid background and practical experience in r...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10018 (Clinton area)</td>\n",
       "      <td>Schireson Associates</td>\n",
       "      <td>We are looking for an analytically-oriented da...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Blackwood Seven</td>\n",
       "      <td>Data Scientists gather and analyze data to sol...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Citi</td>\n",
       "      <td>Develop data and analytic utility tools for tr...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Quantitative Researcher / Data Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>DRW</td>\n",
       "      <td>We are looking for a Data Scientist / Quantita...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Indellient</td>\n",
       "      <td>Big data and analytics, digital content delive...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Intern - Data Analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>YouNow</td>\n",
       "      <td>Someone looking to get into a full time data a...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY 10022 (Midtown area)</td>\n",
       "      <td>Pine River Capital Management</td>\n",
       "      <td>And 3) conducting logistic regression, time se...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ipsos Behavioral Data Group - Behavioral Data ...</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Ipsos North America</td>\n",
       "      <td>We are the Ipsos Behavioral Data Group. Weâre ...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>None</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>UBS</td>\n",
       "      <td>Proficient using C++, VBA, R, SAS, SQL, Oracle...</td>\n",
       "      <td>New York City</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64473</th>\n",
       "      <td>Prospect Research Analyst (Multiple Positions)</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Update information in RE (Raiserâs Edge) datab...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64474</th>\n",
       "      <td>Research Specialist (Extended Temporary)</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Reviews data to be used to write research proj...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64477</th>\n",
       "      <td>Postdoctoral Research Associate I, Obstetrics ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Biostatistical analysis of data sets. Analyze,...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64479</th>\n",
       "      <td>Senior Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>Productive Data Solutions, Inc.</td>\n",
       "      <td>Senior Scientist - Tucson, AZ. Data analysis, ...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64480</th>\n",
       "      <td>Cloud Framework and Application Software Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ 85711 (Rosemont West area)</td>\n",
       "      <td>Rincon Research Corporation</td>\n",
       "      <td>Implementing Engineering Algorithms in C, C++,...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64481</th>\n",
       "      <td>Research Software Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ 85711 (Rosemont West area)</td>\n",
       "      <td>Rincon Research Corporation</td>\n",
       "      <td>Implementing Engineering Algorithms in C, C++,...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64482</th>\n",
       "      <td>Advanced Software Research Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ 85711 (Rosemont West area)</td>\n",
       "      <td>Rincon Research Corporation</td>\n",
       "      <td>Implementing Engineering Algorithms in C, C++,...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64484</th>\n",
       "      <td>Animal Health Care Technician</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>This includes general health, date of birth, v...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64487</th>\n",
       "      <td>Senior Operations Research Simulation Develope...</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>Foreground Security</td>\n",
       "      <td>Are you curious by nature and always seeking t...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64488</th>\n",
       "      <td>Senior Operations Research Simulation Develope...</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>Raytheon</td>\n",
       "      <td>Are you curious by nature and always seeking t...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64489</th>\n",
       "      <td>Data Entry Technician</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>Productive Data Solutions, Inc.</td>\n",
       "      <td>DATA ENTRY TECHNICIAN. Productive Data Solutio...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64491</th>\n",
       "      <td>Medical Laboratory Scientist I</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ 85704</td>\n",
       "      <td>Sonora Quest</td>\n",
       "      <td>Monitors and controls inventory and assists in...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64492</th>\n",
       "      <td>Professor, Sleep and Circadian Biology (T/TE)(...</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>The Sleep Scientist will establish a successfu...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64493</th>\n",
       "      <td>Cathode Scientist</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ 85756</td>\n",
       "      <td>Sion Power</td>\n",
       "      <td>Review/Analyze data from experiments and imple...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64494</th>\n",
       "      <td>Manager, Analytical Mass Spectrometry</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Lead a team of staff scientists with expertise...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64495</th>\n",
       "      <td>Engineer (Electrical) (ETE)</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Expertise in field data transmission and analy...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64496</th>\n",
       "      <td>Soil Scientist/Hydrogeologist</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ 85716 (Palo Verde area)</td>\n",
       "      <td>GeoSystems Analysis, Inc.</td>\n",
       "      <td>SQL), computer programming and data processing...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64497</th>\n",
       "      <td>Director, BIO5 Institute (UPDATED)</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>The BIO5 Institute is committed to training th...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64498</th>\n",
       "      <td>Research Technician (Temporary)</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Perform data collection and analysis. The Depa...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64499</th>\n",
       "      <td>Telescope Optical Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>Association of Universities for Research in As...</td>\n",
       "      <td>Delivering the science instrument, the Data Ma...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64500</th>\n",
       "      <td>GOPS Advanced Geolocation Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ 85711 (Rosemont West area)</td>\n",
       "      <td>Rincon Research Corporation</td>\n",
       "      <td>Core responsibilities include creative problem...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64501</th>\n",
       "      <td>Advanced Software Development Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ 85711 (Rosemont West area)</td>\n",
       "      <td>Rincon Research Corporation</td>\n",
       "      <td>Visualization of large engineering data. You a...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64502</th>\n",
       "      <td>Electrical Engineer (Oracle, AZ)</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>Design data acquisition and control systems. W...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64503</th>\n",
       "      <td>Project Coordinator, Associate</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>Productive Data Solutions, Inc.</td>\n",
       "      <td>Productive Data Solutions, Inc. Compiles repor...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64504</th>\n",
       "      <td>Software Engineer - Java / Tucson</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>NBI Resources</td>\n",
       "      <td>Our core team of Computer scientists and Data ...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64507</th>\n",
       "      <td>Software Architect</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ 85711 (Rosemont West area)</td>\n",
       "      <td>Rincon Research Corporation</td>\n",
       "      <td>This individual will also create effective use...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64513</th>\n",
       "      <td>QA Engineer</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>NBI Resources</td>\n",
       "      <td>Maintaining test data repository. Our core tea...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64514</th>\n",
       "      <td>Senior Design Quality Engineer-Reagents</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>Productive Data Solutions, Inc.</td>\n",
       "      <td>Productive Data Solutions, Inc. Presents data ...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64515</th>\n",
       "      <td>Assistant, Associate or Full Research Scientis...</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>University of Arizona</td>\n",
       "      <td>To be considered at the level of Research Scie...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64516</th>\n",
       "      <td>Senior Cloud Solutions Architect</td>\n",
       "      <td>None</td>\n",
       "      <td>Tucson, AZ</td>\n",
       "      <td>Association of Universities for Research in As...</td>\n",
       "      <td>These data will include a nightly stream of al...</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10730 rows Ã 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               job_title salary  \\\n",
       "0      Machine Learning Engineer (Associate) - Intell...   None   \n",
       "1                                         Data Scientist   None   \n",
       "3                       Data Scientist, Forecast Analyst   None   \n",
       "4                              Data Scientist, Analytics   None   \n",
       "5                Data Scientist - Test & Learn Analytics   None   \n",
       "6                                         Data Scientist   None   \n",
       "8                                         Data Scientist   None   \n",
       "9                                         Data Scientist   None   \n",
       "10                                        Data Scientist   None   \n",
       "11                              Data Scientist - Pricing   None   \n",
       "12                                        Data Scientist   None   \n",
       "13                             Machine Learning Engineer   None   \n",
       "14                                        Data Scientist   None   \n",
       "15                      Multi-Asset Quantitative Analyst   None   \n",
       "16                                        Data Scientist   None   \n",
       "17                   Applied Researcher / Data Scientist   None   \n",
       "18                                        Data Scientist   None   \n",
       "19     Data Scientist (Associate) - Wholesale Solutio...   None   \n",
       "20     Quantitative Researcher/Analyst â Statistical ...   None   \n",
       "21          Data Scientist, Economic Consulting Practice   None   \n",
       "24                                     Data Scientist II   None   \n",
       "25                                          Data Analyst   None   \n",
       "26                                        Data Scientist   None   \n",
       "27                                  Quantitative Analyst   None   \n",
       "28              Quantitative Researcher / Data Scientist   None   \n",
       "29                             Machine Learning Engineer   None   \n",
       "31                                Intern - Data Analysis   None   \n",
       "32                                  Quantitative Analyst   None   \n",
       "33     Ipsos Behavioral Data Group - Behavioral Data ...   None   \n",
       "34                                  Quantitative Analyst   None   \n",
       "...                                                  ...    ...   \n",
       "64473     Prospect Research Analyst (Multiple Positions)   None   \n",
       "64474           Research Specialist (Extended Temporary)   None   \n",
       "64477  Postdoctoral Research Associate I, Obstetrics ...   None   \n",
       "64479                                   Senior Scientist   None   \n",
       "64480  Cloud Framework and Application Software Engineer   None   \n",
       "64481                         Research Software Engineer   None   \n",
       "64482                Advanced Software Research Engineer   None   \n",
       "64484                      Animal Health Care Technician   None   \n",
       "64487  Senior Operations Research Simulation Develope...   None   \n",
       "64488  Senior Operations Research Simulation Develope...   None   \n",
       "64489                              Data Entry Technician   None   \n",
       "64491                     Medical Laboratory Scientist I   None   \n",
       "64492  Professor, Sleep and Circadian Biology (T/TE)(...   None   \n",
       "64493                                  Cathode Scientist   None   \n",
       "64494              Manager, Analytical Mass Spectrometry   None   \n",
       "64495                        Engineer (Electrical) (ETE)   None   \n",
       "64496                      Soil Scientist/Hydrogeologist   None   \n",
       "64497                 Director, BIO5 Institute (UPDATED)   None   \n",
       "64498                    Research Technician (Temporary)   None   \n",
       "64499                         Telescope Optical Engineer   None   \n",
       "64500                 GOPS Advanced Geolocation Engineer   None   \n",
       "64501             Advanced Software Development Engineer   None   \n",
       "64502                   Electrical Engineer (Oracle, AZ)   None   \n",
       "64503                     Project Coordinator, Associate   None   \n",
       "64504                  Software Engineer - Java / Tucson   None   \n",
       "64507                                 Software Architect   None   \n",
       "64513                                        QA Engineer   None   \n",
       "64514            Senior Design Quality Engineer-Reagents   None   \n",
       "64515  Assistant, Associate or Full Research Scientis...   None   \n",
       "64516                   Senior Cloud Solutions Architect   None   \n",
       "\n",
       "                                          location  \\\n",
       "0                New York, NY 10001 (Chelsea area)   \n",
       "1                                     New York, NY   \n",
       "3                                     New York, NY   \n",
       "4                                     New York, NY   \n",
       "5      New York, NY 10003 (Greenwich Village area)   \n",
       "6                                    Manhattan, NY   \n",
       "8                                     New York, NY   \n",
       "9           New York, NY 10012 (Little Italy area)   \n",
       "10                                    New York, NY   \n",
       "11     New York, NY 10003 (Greenwich Village area)   \n",
       "12                                    New York, NY   \n",
       "13                                    Brooklyn, NY   \n",
       "14                                    New York, NY   \n",
       "15                                    New York, NY   \n",
       "16                                    New York, NY   \n",
       "17               New York, NY 10011 (Chelsea area)   \n",
       "18                                    New York, NY   \n",
       "19               New York, NY 10001 (Chelsea area)   \n",
       "20                                    New York, NY   \n",
       "21                              New York, NY 10036   \n",
       "24               New York, NY 10112 (Midtown area)   \n",
       "25               New York, NY 10018 (Clinton area)   \n",
       "26                                    New York, NY   \n",
       "27                                    New York, NY   \n",
       "28                                    New York, NY   \n",
       "29                                    New York, NY   \n",
       "31                                    New York, NY   \n",
       "32               New York, NY 10022 (Midtown area)   \n",
       "33                                    New York, NY   \n",
       "34                                    New York, NY   \n",
       "...                                            ...   \n",
       "64473                                   Tucson, AZ   \n",
       "64474                                   Tucson, AZ   \n",
       "64477                                   Tucson, AZ   \n",
       "64479                                   Tucson, AZ   \n",
       "64480        Tucson, AZ 85711 (Rosemont West area)   \n",
       "64481        Tucson, AZ 85711 (Rosemont West area)   \n",
       "64482        Tucson, AZ 85711 (Rosemont West area)   \n",
       "64484                                   Tucson, AZ   \n",
       "64487                                   Tucson, AZ   \n",
       "64488                                   Tucson, AZ   \n",
       "64489                                   Tucson, AZ   \n",
       "64491                             Tucson, AZ 85704   \n",
       "64492                                   Tucson, AZ   \n",
       "64493                             Tucson, AZ 85756   \n",
       "64494                                   Tucson, AZ   \n",
       "64495                                   Tucson, AZ   \n",
       "64496           Tucson, AZ 85716 (Palo Verde area)   \n",
       "64497                                   Tucson, AZ   \n",
       "64498                                   Tucson, AZ   \n",
       "64499                                   Tucson, AZ   \n",
       "64500        Tucson, AZ 85711 (Rosemont West area)   \n",
       "64501        Tucson, AZ 85711 (Rosemont West area)   \n",
       "64502                                   Tucson, AZ   \n",
       "64503                                   Tucson, AZ   \n",
       "64504                                   Tucson, AZ   \n",
       "64507        Tucson, AZ 85711 (Rosemont West area)   \n",
       "64513                                   Tucson, AZ   \n",
       "64514                                   Tucson, AZ   \n",
       "64515                                   Tucson, AZ   \n",
       "64516                                   Tucson, AZ   \n",
       "\n",
       "                                                 company  \\\n",
       "0                                        JP Morgan Chase   \n",
       "1                                            GameChanger   \n",
       "3                                           NBCUniversal   \n",
       "4                                               Facebook   \n",
       "5                                     J.Crew Group, Inc.   \n",
       "6                                               Diaspark   \n",
       "8                                     Blue State Digital   \n",
       "9                                                 Meetup   \n",
       "10                                          ThreatMetrix   \n",
       "11                                    J.Crew Group, Inc.   \n",
       "12                                                Tumblr   \n",
       "13                                                Pienso   \n",
       "14                                             LearnVest   \n",
       "15                                        Voya Financial   \n",
       "16                                            HelloFresh   \n",
       "17                                             eBay Inc.   \n",
       "18                                                CompIQ   \n",
       "19                                       JP Morgan Chase   \n",
       "20                                Global Trading Systems   \n",
       "21                                  FTI Consulting, Inc.   \n",
       "24                                               Comcast   \n",
       "25                                  Schireson Associates   \n",
       "26                                       Blackwood Seven   \n",
       "27                                                  Citi   \n",
       "28                                                   DRW   \n",
       "29                                            Indellient   \n",
       "31                                                YouNow   \n",
       "32                         Pine River Capital Management   \n",
       "33                                   Ipsos North America   \n",
       "34                                                   UBS   \n",
       "...                                                  ...   \n",
       "64473                              University of Arizona   \n",
       "64474                              University of Arizona   \n",
       "64477                              University of Arizona   \n",
       "64479                    Productive Data Solutions, Inc.   \n",
       "64480                        Rincon Research Corporation   \n",
       "64481                        Rincon Research Corporation   \n",
       "64482                        Rincon Research Corporation   \n",
       "64484                              University of Arizona   \n",
       "64487                                Foreground Security   \n",
       "64488                                           Raytheon   \n",
       "64489                    Productive Data Solutions, Inc.   \n",
       "64491                                       Sonora Quest   \n",
       "64492                              University of Arizona   \n",
       "64493                                         Sion Power   \n",
       "64494                              University of Arizona   \n",
       "64495                              University of Arizona   \n",
       "64496                          GeoSystems Analysis, Inc.   \n",
       "64497                              University of Arizona   \n",
       "64498                              University of Arizona   \n",
       "64499  Association of Universities for Research in As...   \n",
       "64500                        Rincon Research Corporation   \n",
       "64501                        Rincon Research Corporation   \n",
       "64502                              University of Arizona   \n",
       "64503                    Productive Data Solutions, Inc.   \n",
       "64504                                      NBI Resources   \n",
       "64507                        Rincon Research Corporation   \n",
       "64513                                      NBI Resources   \n",
       "64514                    Productive Data Solutions, Inc.   \n",
       "64515                              University of Arizona   \n",
       "64516  Association of Universities for Research in As...   \n",
       "\n",
       "                                             description search_location  \\\n",
       "0      JP Morgan Intelligent Solutions (JPMIS) is a n...   New York City   \n",
       "1      As a Data Analyst, youâll transform the teraby...   New York City   \n",
       "3      Experience with data visualization techniques ...   New York City   \n",
       "4      The Data Scientist Analytics role has work acr...   New York City   \n",
       "5      Data Scientist â Test and Learn Analytics. Han...   New York City   \n",
       "6      Team-oriented (we run a meritocracy), creative...   New York City   \n",
       "8      Use data to build a better world. You will be ...   New York City   \n",
       "9      3+ years working with data analytics, data war...   New York City   \n",
       "10     As a Data Scientist, youâll use data from the ...   New York City   \n",
       "11     J.Crew is seeking a Data Scientist with an emp...   New York City   \n",
       "12     Influence product decisions through data analy...   New York City   \n",
       "13     Youâre a machine learning backend engineer, ap...   New York City   \n",
       "14     Ability to tell a story with data â What does ...   New York City   \n",
       "15     Thoughtful process of analyzing data and probl...   New York City   \n",
       "16     Data Scientist Job Description:. A data junkie...   New York City   \n",
       "17     Youâll work with world-class data scientists a...   New York City   \n",
       "18     We're looking for a highly analytical data sci...   New York City   \n",
       "19     JPMIS Data Scientist is responsible for develo...   New York City   \n",
       "20     We are looking for a quantitative researcher w...   New York City   \n",
       "21     Data Scientist, Economic Consulting Practice. ...   New York City   \n",
       "24     Solid background and practical experience in r...   New York City   \n",
       "25     We are looking for an analytically-oriented da...   New York City   \n",
       "26     Data Scientists gather and analyze data to sol...   New York City   \n",
       "27     Develop data and analytic utility tools for tr...   New York City   \n",
       "28     We are looking for a Data Scientist / Quantita...   New York City   \n",
       "29     Big data and analytics, digital content delive...   New York City   \n",
       "31     Someone looking to get into a full time data a...   New York City   \n",
       "32     And 3) conducting logistic regression, time se...   New York City   \n",
       "33     We are the Ipsos Behavioral Data Group. Weâre ...   New York City   \n",
       "34     Proficient using C++, VBA, R, SAS, SQL, Oracle...   New York City   \n",
       "...                                                  ...             ...   \n",
       "64473  Update information in RE (Raiserâs Edge) datab...          Tucson   \n",
       "64474  Reviews data to be used to write research proj...          Tucson   \n",
       "64477  Biostatistical analysis of data sets. Analyze,...          Tucson   \n",
       "64479  Senior Scientist - Tucson, AZ. Data analysis, ...          Tucson   \n",
       "64480  Implementing Engineering Algorithms in C, C++,...          Tucson   \n",
       "64481  Implementing Engineering Algorithms in C, C++,...          Tucson   \n",
       "64482  Implementing Engineering Algorithms in C, C++,...          Tucson   \n",
       "64484  This includes general health, date of birth, v...          Tucson   \n",
       "64487  Are you curious by nature and always seeking t...          Tucson   \n",
       "64488  Are you curious by nature and always seeking t...          Tucson   \n",
       "64489  DATA ENTRY TECHNICIAN. Productive Data Solutio...          Tucson   \n",
       "64491  Monitors and controls inventory and assists in...          Tucson   \n",
       "64492  The Sleep Scientist will establish a successfu...          Tucson   \n",
       "64493  Review/Analyze data from experiments and imple...          Tucson   \n",
       "64494  Lead a team of staff scientists with expertise...          Tucson   \n",
       "64495  Expertise in field data transmission and analy...          Tucson   \n",
       "64496  SQL), computer programming and data processing...          Tucson   \n",
       "64497  The BIO5 Institute is committed to training th...          Tucson   \n",
       "64498  Perform data collection and analysis. The Depa...          Tucson   \n",
       "64499  Delivering the science instrument, the Data Ma...          Tucson   \n",
       "64500  Core responsibilities include creative problem...          Tucson   \n",
       "64501  Visualization of large engineering data. You a...          Tucson   \n",
       "64502  Design data acquisition and control systems. W...          Tucson   \n",
       "64503  Productive Data Solutions, Inc. Compiles repor...          Tucson   \n",
       "64504  Our core team of Computer scientists and Data ...          Tucson   \n",
       "64507  This individual will also create effective use...          Tucson   \n",
       "64513  Maintaining test data repository. Our core tea...          Tucson   \n",
       "64514  Productive Data Solutions, Inc. Presents data ...          Tucson   \n",
       "64515  To be considered at the level of Research Scie...          Tucson   \n",
       "64516  These data will include a nightly stream of al...          Tucson   \n",
       "\n",
       "      salary_info  \n",
       "0            None  \n",
       "1            None  \n",
       "3            None  \n",
       "4            None  \n",
       "5            None  \n",
       "6            None  \n",
       "8            None  \n",
       "9            None  \n",
       "10           None  \n",
       "11           None  \n",
       "12           None  \n",
       "13           None  \n",
       "14           None  \n",
       "15           None  \n",
       "16           None  \n",
       "17           None  \n",
       "18           None  \n",
       "19           None  \n",
       "20           None  \n",
       "21           None  \n",
       "24           None  \n",
       "25           None  \n",
       "26           None  \n",
       "27           None  \n",
       "28           None  \n",
       "29           None  \n",
       "31           None  \n",
       "32           None  \n",
       "33           None  \n",
       "34           None  \n",
       "...           ...  \n",
       "64473        None  \n",
       "64474        None  \n",
       "64477        None  \n",
       "64479        None  \n",
       "64480        None  \n",
       "64481        None  \n",
       "64482        None  \n",
       "64484        None  \n",
       "64487        None  \n",
       "64488        None  \n",
       "64489        None  \n",
       "64491        None  \n",
       "64492        None  \n",
       "64493        None  \n",
       "64494        None  \n",
       "64495        None  \n",
       "64496        None  \n",
       "64497        None  \n",
       "64498        None  \n",
       "64499        None  \n",
       "64500        None  \n",
       "64501        None  \n",
       "64502        None  \n",
       "64503        None  \n",
       "64504        None  \n",
       "64507        None  \n",
       "64513        None  \n",
       "64514        None  \n",
       "64515        None  \n",
       "64516        None  \n",
       "\n",
       "[10730 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates(inplace=True)\n",
    "df[ [d for d in df.salary_info.isnull()]]\n",
    "# I will deal with weekly and hourly salaries later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "7d4bc860-b214-4f75-9cd0-b234830b1ec2"
   },
   "source": [
    "#### Write a function that takes a salary string and converts it to a number, averaging a salary range if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting salary column to numbers, averaging over a range.\n",
    "df['salary'] = df.salary.apply(clean_salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean = df[df.salary.isnull() == False]\n",
    "df_clean.sort_values('salary')\n",
    "# Merging my cost of living data with my dataframe.\n",
    "# Sub selecting cost of living data for easier formatting.\n",
    "df_cost_living = df_cost_living[['search_location','cost_index']]\n",
    "df_clean = df_clean.merge(df_cost_living, on='search_location', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean['salary_adjusted'] = salary_adjust(df_clean.salary, df_clean.salary_info)\n",
    "df_clean_simple = df_clean[df_clean.salary > 20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>cost_index</th>\n",
       "      <th>salary_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>824.000000</td>\n",
       "      <td>824.000000</td>\n",
       "      <td>824.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73694.608076</td>\n",
       "      <td>187.519417</td>\n",
       "      <td>91644.296602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>58076.281422</td>\n",
       "      <td>36.539226</td>\n",
       "      <td>45833.854554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.010000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>20820.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6499.750000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>55817.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70399.500000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>80000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113125.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>120000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>275000.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>275000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              salary  cost_index  salary_adjusted\n",
       "count     824.000000  824.000000       824.000000\n",
       "mean    73694.608076  187.519417     91644.296602\n",
       "std     58076.281422   36.539226     45833.854554\n",
       "min        10.010000  125.000000     20820.800000\n",
       "25%      6499.750000  161.000000     55817.875000\n",
       "50%     70399.500000  183.000000     80000.000000\n",
       "75%    113125.000000  213.000000    120000.000000\n",
       "max    275000.000000  251.000000    275000.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>salary</th>\n",
       "      <th>cost_index</th>\n",
       "      <th>salary_adjusted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>607.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>607.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99517.644152</td>\n",
       "      <td>190.581549</td>\n",
       "      <td>99517.644152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45190.206843</td>\n",
       "      <td>38.093894</td>\n",
       "      <td>45190.206843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22500.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>22500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>64500.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>64500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91166.500000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>91166.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>129412.500000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>129412.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>275000.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>275000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              salary  cost_index  salary_adjusted\n",
       "count     607.000000  607.000000       607.000000\n",
       "mean    99517.644152  190.581549     99517.644152\n",
       "std     45190.206843   38.093894     45190.206843\n",
       "min     22500.000000  125.000000     22500.000000\n",
       "25%     64500.000000  161.000000     64500.000000\n",
       "50%     91166.500000  186.000000     91166.500000\n",
       "75%    129412.500000  234.000000    129412.500000\n",
       "max    275000.000000  251.000000    275000.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean_simple.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When adjusting salaries I get more data points, but the average salary becomes lower. I think this is still a valid approach to make. And I still have the data marked to determine which values are adjusted and which are not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "search_location\n",
       "New York City      88\n",
       "Washington D.C.    59\n",
       "Tacoma             36\n",
       "Boston             35\n",
       "San Francisco      34\n",
       "San Jose           32\n",
       "Chicago            31\n",
       "Oakland            30\n",
       "Seattle            29\n",
       "Atlanta            26\n",
       "Name: job_title, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.groupby('search_location').count().sort_values('salary', ascending=False)['job_title'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting salaries using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the salary was low or high. Compute the median salary and create a new binary variable that is true when the salary is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the salary value here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW salary.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extreme salaries. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of salaries, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "87a17d3d-b7f4-4747-9f75-f9af1d18a174"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low salary using Sklearn. Start by ONLY using the location as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a job title.\n",
    "- For example, create a feature that represents whether 'Senior' is in the title or whether 'Manager' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value?\n",
    "- After creating these variables, use count-vectorizer to create features based on the words in the job titles.\n",
    "- Build a new random forest model with location and these new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process with a non-tree-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "db045898-1d2d-4af2-8e79-437c4c7546b4"
   },
   "source": [
    "#### Bonus: Use Count Vectorizer from scikit-learn to create features from the job descriptions. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
